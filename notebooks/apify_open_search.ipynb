{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f138b410-f957-4323-a1f2-5bbb4adc1bf6",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to scrape potential job postings, and store them in Elasticsearch. The data will be subsequently analyzed in Kibana. We will use pre-written scrapers on [Apify's marketplace](https://console.apify.com/). Specifically, we will use [Google Jobs Scraper](https://console.apify.com/actors/SpK8RxKhIgV6BWOz9/console) actor. We will start by scraping the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dd1cb0e-ae21-422f-ad14-82ebfce68ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T02:25:40.653567497Z",
     "start_time": "2024-01-06T02:25:40.566154723Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "from apify_client import ApifyClient\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.client import IndicesClient\n",
    "import os\n",
    "import re\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b211830-d261-435a-b7f2-3f1c95355ea9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T02:26:01.664198097Z",
     "start_time": "2024-01-06T02:26:01.661115728Z"
    }
   },
   "outputs": [],
   "source": [
    "# ENVIRONMENT VARIABLES\n",
    "APIFY_TOKEN = os.environ[\"brave_apify_token\"]\n",
    "OPENSEARCH_USER = os.environ[\"opensearch_user\"]\n",
    "OPENSEARCH_PWD = os.environ[\"opensearch_pwd\"]\n",
    "\n",
    "# APIFY INPUT\n",
    "ACTOR_ID = \"SpK8RxKhIgV6BWOz9\"\n",
    "\n",
    "TITLES = [\n",
    "    \"Machine Learning Engineer\", \n",
    "    \"Data Scientist\", \n",
    "    \"MLOps Engineer\", \n",
    "    \"Data Analyst\", \n",
    "    \"Data Engineer\"\n",
    "]\n",
    "\n",
    "NUM_PAGES = 1\n",
    "MAX_CONCURRENCY = 10\n",
    "\n",
    "BASE_QUERIES = {\n",
    "    \"maxPagesPerQuery\": NUM_PAGES,\n",
    "    \"csvFriendlyOutput\": False,\n",
    "    \"countryCode\": \"ca\",\n",
    "    \"languageCode\": \"\",\n",
    "    \"maxConcurrency\": MAX_CONCURRENCY,\n",
    "    \"saveHtml\": False,\n",
    "    \"saveHtmlToKeyValueStore\": False,\n",
    "    \"includeUnfilteredResults\": False,\n",
    "}\n",
    "QUERY_URL = \"https://www.google.ca/search?q=JOB&ibp=htl;jobs&uule=w+CAIQICIGQ2FuYWRh\"\n",
    "\n",
    "# OPENSEARCH INPUT\n",
    "OPENSEARCH_HOST = 'search-swift-hire-dev-jfmldmym4cfbiwdhwmtuqq6ihy.us-west-2.es.amazonaws.com'\n",
    "INDEX_NAME = 'jobs_harpreet_matharoo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fa333-c137-42da-9f34-95790aa81f5d",
   "metadata": {},
   "source": [
    "Now, we prepare the queries based on the variables defined above and run the actors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2958087a-747e-4cf3-9697-321ca40294a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS QUERIES TO CREATE A QUERY FOR EACH SEARCHED TITLE\n",
    "processed_titles = [\"%20\".join(title.split()) for title in TITLES]\n",
    "query_urls = [re.sub(\"JOB\", title, QUERY_URL) for title in processed_titles]\n",
    "\n",
    "# PREPARE QUERIES\n",
    "queries = []\n",
    "for query_url in query_urls:\n",
    "    query = BASE_QUERIES.copy()\n",
    "    query[\"queries\"] = query_url\n",
    "    queries.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e88b6353-134e-46c1-9467-c8788af3d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ApifyClient with your API token\n",
    "client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "items = []\n",
    "# Run the Actor and wait for it to finish\n",
    "for query in queries:\n",
    "    run = client.actor(ACTOR_ID).call(run_input=query)\n",
    "    \n",
    "    # Fetch and print Actor results from the run's dataset (if there are any)\n",
    "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "        items.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948af72-0877-4484-83eb-f0118a303562",
   "metadata": {},
   "source": [
    "Finally, we create an index in Elasticsearch and add all the collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d5859dc-faa1-4cbe-8ac2-7237539af332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Elastic Search Client and Add the Scraped Records to the Index\n",
    "opensearch_client = OpenSearch(\n",
    "            hosts=[{'host': OPENSEARCH_HOST, 'port': 443}],\n",
    "            http_compress=True,  # enables gzip compression for request bodies\n",
    "            http_auth=(OPENSEARCH_USER, OPENSEARCH_PWD),\n",
    "            use_ssl=True,\n",
    "            ssl_assert_hostname=False,\n",
    "            ssl_show_warn=False,\n",
    "        )\n",
    "\n",
    "# CREATE an Index to Store the Jobs\n",
    "if not IndicesClient(opensearch_client).exists(index=INDEX_NAME):\n",
    "    opensearch_client.indices.create(index=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f1d5abf-a059-4358-bc56-9b3d83b8d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'57b31242003613e46d50e9dbdf1c01c5a0c91de0c914ba86c7ca0a10dc834542'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha256(str(items[0]['googleJobs']).encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30fc64cd-b146-429a-a4f0-6ce8223bd454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abc'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abc\".encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fed86a64-8319-4080-a9a3-12da336361f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    for _, job_data in enumerate(item['googleJobs']):\n",
    "        \n",
    "        # Create a Unique Identifier with SHA-256\n",
    "        encoded_jd = str(job_data).encode(\"utf-8\")\n",
    "        id = hashlib.sha256(encoded_jd).hexdigest()\n",
    "\n",
    "        # Check if the id already exists \n",
    "        if not opensearch_client.exists(index=INDEX_NAME, id=id):\n",
    "            opensearch_client.create(\n",
    "                index=INDEX_NAME,\n",
    "                id=id,\n",
    "                body=job_data\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b62195-17c3-4b40-a5d2-9b1e7f904deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'jobs_harpreet_matharoo',\n",
       " '_id': '19',\n",
       " '_version': 1,\n",
       " '_seq_no': 7,\n",
       " '_primary_term': 1,\n",
       " 'found': True,\n",
       " '_source': {'title': 'Data Scientist',\n",
       "  'companyName': 'Overbond',\n",
       "  'location': '  Canada   ',\n",
       "  'via': 'via Lever',\n",
       "  'description': \"About Us\\n\\nOverbond is a developer of artificial intelligence (AI)-driven real-time data streams for bond trading automation. Overbond offers the most advanced bond trading data streams and execution management system (EMS) in the market. The Overbond data streams and analytics can be integrated into the systems and workflow of any and every fixed income trading desk in the world.\\n\\nOverbond helps fixed income trading desks overcome the lack of a complete and centralized pricing and transaction data source for the bond markets, execute more client trades, increase the profitably of the trades that are executed, conduct pre-trade and post-trade analyses, monitor prices and risk and prepare reports.\\n\\nThe company serves trading desks in the Americas, Europe and Asia. Overbond is headquartered in Toronto and operates a lab in Montreal that engages academics and post-graduate researchers to conduct advanced research and development in quantitative finance and AI modelling.\\n\\nThe... Opportunity\\n\\nThis exciting new role is available as part of the Overbond product team expansion. The position is a unique opportunity to build creative solutions for complex problems using cutting edge technology. As an expert in data science, you will be in charge of the architecture, integration and analysis of large data sets used for developing machine learning models and generating business insights. We are seeking experienced data scientists who are excited about utilizing latest statistical, machine learning, and predictive analytics techniques to transform unstructured data to creative solutions that will have direct impact on the business of our clients.\\n\\nWhat You'll Do\\n• Collect, analyze and visualize colossal datasets using a variety of emerging technologies to help solidify our understanding of users and improve product decision-making\\n• Assist in design, build and maintain an expanding set of robust predictive models and applications to drive forecast accuracy\\n• Contribute towards data science initiatives to recommend actionable business insights using big data analytics and machine learning techniques\\n• Leverage distributed and open-source computing tools for recommendations, classification, regression, and feature extraction, from logistic regression to matrix factorization, to deep learning neural networks\\n• Prepare detailed documentation to specify data sources, models and algorithms used and developed\\n• Collaborate with the engineering team to deploy models and algorithms in production\\n• Effectively communicate data insights in a non-technical manner to key stakeholders and senior management team\\n\\nWhat You'll Need\\n• Bachelors or Masters degree in relevant disciplines (Mathematics, Computer Science, Statistics or other quantitative related discipline)\\n• 1 - 2 years of experience in data mining, machine learning and statistical modeling\\n• Solid knowledge in regression, time series analysis, tree methods, neural network, sampling\\n• Proven track record of building and demonstrating business value from predictive models and data products\\n• Highly proficient in building statistical and algorithmic models with complex and large data sets such as supervised statistical learning, times-series analysis, regression analysis, data visualization and deep learning\\n• Capability to architect highly scalable distributed systems, using different open source tools\\n• Coding experience in SQL or Python or R\\n• Experience with AWS Kinesis, DynamoDB, Lambda, Redshift, Glue, Athena and Airflow\\n• Familiarity with Overbond product suite: Bond Trading Automation, Liquidity Scoring, Bond real-time pricing, Fixed Income ETF basket pricing, Transaction Cost Analysis (TCA), Margin Optimization and Issuance Propensity models\\n• An entrepreneurial mindset, likes working in an agile environment, driven to ship frequently\\n• Excellent communication and interpersonal skills\\n• Team-oriented, pragmatic, self-starting\\n• Likes to learn and grow with teammates in a highly collaborative and open environment\\n• Understanding of, or interest in, finance and investments\\n\\nWhat We Offer\\n• Opportunity to work on a real product with very demanding paying enterprise clients\\n• Learning and self-development opportunities through online courses and knowledge sharing lecture sessions.\\n• Extended health coverage (Dental, Vision, Drug plan and other medical services)\\n• Life Insurance and AD&D coverage\\n• Paid vacation days, sick days, personal/ emergency days and extended long weekends.\\n• Monthly team lunches and social events (hosted virtually in light of Covid restrictions)\\n\\nSuccessful candidate(s) will have a truly exciting opportunity to be part of the industry leading financial technology company changing the way how global investment banks, institutional investors, corporations and governments access the capital markets. The candidate will work with top notch industry professionals and will be given ample amount of opportunities to learn and contribute.\\n\\nOverbond is committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We welcome applications from: women, Aboriginal persons, persons with disabilities, ethnic minorities, visible minorities, people who identify as LGBT and others who may contribute to diversification in our workplace.\\n\\nAs part of our commitment to accessibility for all persons with disabilities, Overbond will, upon the request of the applicant, provide accommodation during the recruitment process to ensure equal access to applicants with disabilities\",\n",
       "  'jobHighlights': [{'items': [\"About Us\\n\\nOverbond is a developer of artificial intelligence (AI)-driven real-time data streams for bond trading automation. Overbond offers the most advanced bond trading data streams and execution management system (EMS) in the market. The Overbond data streams and analytics can be integrated into the systems and workflow of any and every fixed income trading desk in the world.\\n\\nOverbond helps fixed income trading desks overcome the lack of a complete and centralized pricing and transaction data source for the bond markets, execute more client trades, increase the profitably of the trades that are executed, conduct pre-trade and post-trade analyses, monitor prices and risk and prepare reports.\\n\\nThe company serves trading desks in the Americas, Europe and Asia. Overbond is headquartered in Toronto and operates a lab in Montreal that engages academics and post-graduate researchers to conduct advanced research and development in quantitative finance and AI modelling.\\n\\nThe... Opportunity\\n\\nThis exciting new role is available as part of the Overbond product team expansion. The position is a unique opportunity to build creative solutions for complex problems using cutting edge technology. As an expert in data science, you will be in charge of the architecture, integration and analysis of large data sets used for developing machine learning models and generating business insights. We are seeking experienced data scientists who are excited about utilizing latest statistical, machine learning, and predictive analytics techniques to transform unstructured data to creative solutions that will have direct impact on the business of our clients.\\n\\nWhat You'll Do\\n• Collect, analyze and visualize colossal datasets using a variety of emerging technologies to help solidify our understanding of users and improve product decision-making\\n• Assist in design, build and maintain an expanding set of robust predictive models and applications to drive forecast accuracy\\n• Contribute towards data science initiatives to recommend actionable business insights using big data analytics and machine learning techniques\\n• Leverage distributed and open-source computing tools for recommendations, classification, regression, and feature extraction, from logistic regression to matrix factorization, to deep learning neural networks\\n• Prepare detailed documentation to specify data sources, models and algorithms used and developed\\n• Collaborate with the engineering team to deploy models and algorithms in production\\n• Effectively communicate data insights in a non-technical manner to key stakeholders and senior management team\\n\\nWhat You'll Need\\n• Bachelors or Masters degree in relevant disciplines (Mathematics, Computer Science, Statistics or other quantitative related discipline)\\n• 1 - 2 years of experience in data mining, machine learning and statistical modeling\\n• Solid knowledge in regression, time series analysis, tree methods, neural network, sampling\\n• Proven track record of building and demonstrating business value from predictive models and data products\\n• Highly proficient in building statistical and algorithmic models with complex and large data sets such as supervised statistical learning, times-series analysis, regression analysis, data visualization and deep learning\\n• Capability to architect highly scalable distributed systems, using different open source tools\\n• Coding experience in SQL or Python or R\\n• Experience with AWS Kinesis, DynamoDB, Lambda, Redshift, Glue, Athena and Airflow\\n• Familiarity with Overbond product suite: Bond Trading Automation, Liquidity Scoring, Bond real-time pricing, Fixed Income ETF basket pricing, Transaction Cost Analysis (TCA), Margin Optimization and Issuance Propensity models\\n• An entrepreneurial mindset, likes working in an agile environment, driven to ship frequently\\n• Excellent communication and interpersonal skills\\n• Team-oriented, pragmatic, self-starting\\n• Likes to learn and grow with teammates in a highly collaborative and open environment\\n• Understanding of, or interest in, finance and investments\\n\\nWhat We Offer\\n• Opportunity to work on a real product with very demanding paying enterprise clients\\n• Learning and self-development opportunities through online courses and knowledge sharing lecture sessions.\\n• Extended health coverage (Dental, Vision, Drug plan and other medical services)\\n• Life Insurance and AD&D coverage\\n• Paid vacation days, sick days, personal/ emergency days and extended long weekends.\\n• Monthly team lunches and social events (hosted virtually in light of Covid restrictions)\\n\\nSuccessful candidate(s) will have a truly exciting opportunity to be part of the industry leading financial technology company changing the way how global investment banks, institutional investors, corporations and governments access the capital markets. The candidate will work with top notch industry professionals and will be given ample amount of opportunities to learn and contribute.\\n\\nOverbond is committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We welcome applications from: women, Aboriginal persons, persons with disabilities, ethnic minorities, visible minorities, people who identify as LGBT and others who may contribute to diversification in our workplace.\\n\\nAs part of our commitment to accessibility for all persons with disabilities, Overbond will, upon the request of the applicant, provide accommodation during the recruitment process to ensure equal access to applicants with disabilities\"]}],\n",
       "  'relatedLinks': [{'link': 'http://www.overbond.com/',\n",
       "    'text': 'overbond.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=596109742&ucbcb=1&q=Overbond&sa=X&ved=0ahUKEwjNuqLq08eDAxVx2gIHHVrzBYkQmJACCLoL',\n",
       "    'text': 'See web results for Overbond'}],\n",
       "  'extras': ['Full-time'],\n",
       "  'metadata': {'scheduleType': 'Full-time'},\n",
       "  'applyLink': {'title': 'Apply on Lever',\n",
       "   'link': 'https://jobs.lever.co/overbond/4340462d-acbd-4881-a00d-be97789a8edc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opensearch_client.get(INDEX_NAME, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec60c3-3a45-46d4-a34b-56e7410a9d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
